上完這次的課程，同樣也是真的學到非常多的知識，不論是對於AI的理解以及一些AI的算法像是Gradient Descend, CNN, RNN都有更深入的了解。自己本來是對AI沒什麼興趣的，也沒有寫過AI相關的程式，只是最近AI很熱門再加上大學剛好考上淡江人工智慧學系，所以才報名了這個課程。但是上完課後，反而對AI更有興趣了！我很喜歡線上課程的形式，只是Google Meet不能直接傳圖片比較可惜，課程的內容都淺顯易懂，老師也會帶我們一步步講解，讓我們能更理解課程的內容，老師真的很用心，簡報做得很精美，也都會有耐心地回答學生的問題，態度也很和藹可親，我覺得是一位能激起學生求知慾的教授。

我最喜歡這個課程的部份是課程最後的驗收，雖然老師是因為發證書需要有一些標準才有這個環節的，但是因為我很喜歡動手去實作，因為實作總是能學到很多東西，我也很享受實作中一步步解決問題的過程，再加上驗收通過的標準也不難，只要準確率超過75%就可以了。這次的驗收我花了最大的努力去完成，從題目公佈的那天起，我就開始在訓練model，一開始我只是隨便加幾層卷積，結果就有75~76%準確率了，但是我覺得還不夠好，想說至少要到80%，所以我就一直不斷地trial and error，努力結合課程以及自己的知識把準確率推到最高。不過因為我訓練太多次了，所以colab不讓我用GPU，要等幾個小時才能用，所以我還用別的帳號去跑，結果訓練太多也用不了GPU了，最後總共被鎖了3次，而且沒有GPU的話，一次epoch要跑1小時左右，用GPU只要30s左右，速度差了一百多倍！所以花了很多時間在訓練跟等解鎖GPU。但是，努力過後的果實總是甜美的，經過了2天2夜的思考與測試，最後驗收當天測出的最高準確率是89.26％！快將近到達90％，而其他人主要是在75~82％之間，可以看出我花了很多時間去做調整與訓練我的model。為什麼我的model跟別人的model會有這麼大的差異呢？我覺得原因可能是以下3點：model架構、資料強度與資料量、訓練方式。

首先，model架構我是參考了VGG16的架構，並且用4次迴圈去建卷積層，每次迴圈都讓卷積核心數乘兩倍（初始為64），並加2~3層卷積還有一層BatchNormalization以及MaxPooling2D。最後再做flatten，用兩層Dense每層一次Dropout(0.1)，減少Overfitting，model 總共約24層。相較之下，其他人的卷積層就不像我的這麼複雜，可能就像我一開始一樣就只加3~4層卷積，這樣雖然可以到75%，但是要更好的話，可以再更複雜。但是也不是越複雜越好，過於複雜好像會導致Overfitting的情況。以我這個架構的話大約可以到78～80%左右的準確率。

再來，資料強度與資料量的部份，一開始我也是直接用原始的資料去訓練，但是這樣一樣只有78~80%左右的準確率，之後考慮到資料強度，可以用老師教過的ImageDataGenerator，可以對資料做一些transform，增加資料強度，可讓準確率到81~82%。但是我又考慮到資料量的部份，我覺得一倍的資料量太少了，所以我就把原始的資料再複製一份，然後再做資料增強，這樣就可以得到兩倍的資料且都不會重複，那時沒有想太多就直接這樣做了，但之後驗收後有問老師這樣重複一份資料再增強會不會比較好，老師說因為他也沒有這樣試過，所以他也不太確定，但老師認為應該不會，因為資料都是一樣的只是多了一倍，增強的資料應該也是會一樣，最後說我可以去測試看看。整個課程結束後我有自己去測試過了，結論就是用重複一份資料再做增強的方式，確實可以提昇準確率，大約可以高個2~3%，我認為這是因為ImageDataGenerator不管資料是不是一樣都會隨機產生出不同的資料出來，所以出來的資料也會不同，我也實際將資料量簡化為1個並複製再做增強，出來的2個資料也是不一樣的，但看得出來是根據原本的資料來做變化，像是有一張圖片有翻轉、偏左，另一張可能是沒翻轉、偏右。當時我就用了這個方法讓準確率到了84~85%。

最後，訓練的部份，我是分兩次訓練，這是因為我一開始只有訓練一次，可能是用增強的資料，或是用原始的資料。但是後來我意識到增強過的資料跟原始的資料都是不同的資料，兩份都拿來訓練應該會比較好，所以我決定分兩次訓練。第一次訓練是用增強過的兩倍資料，然後第二次再用原始資料並用更小的學習率(0.0003)去趨近原始的資料，其實感覺有點像是考試先給你難的考題，然後再給你原本的考題，然後你就會覺得原本的考題比較簡單的概念。然後每一次訓練跑40Epochs，還有設一個EarlyStopping(monitor='val_loss', patience = 8)，即為val_loss在8次Epochs內沒有比較好就停止訓練。我用這樣的方法，讓準確率再提昇3~4%，差不多是88~89%。看到89.26%的當下真的很感動，我會得到這個89%，並不是因為我比較聰明，也不是我運氣比較好，而是我願意花時間在這次的作業上，並且在最後的兩天展現課程中所得到的知識，在這兩天內總共訓練的時間至少超過了十小時，也寫了快十個版本，最後終於得到還不錯的結果，而且有些方法還是靠自己想的，這使我得到很大的成就感，也燃起了我對AI領域的興趣，更讓我再次體會到了動手實作的魅力。

最後的最後，真的非常感謝這四周授課的兩位教授，短短四周內真的學到了很多知識，讓我有能力可以處理一些資訊或是製作一些工具，提升自己的價值。在這四周內我也落實coding365的精神，幾乎每天都會寫一些程式，不論是課堂的練習，還是自己想寫的小工具，甚至有一週還花了23小時的時間在coding。希望課程的時間或週次可以再長一些，因為兩位教授的課總是能激起我們的求知慾，想要越學越多。尤其是AI的課程，雖然李教授已經教到比原本預定的課程還多出四個章節了，但是感覺AI還有非常多的東西可以講。總之，最後還是非常感謝北科大提供如此高質量的課程，讓我這四周過得非常有意義！

p.s. 課程結束後，又花幾個小時將準確率提升到最高93.1%，比原本高了3~4%，方式僅是將dataGenerator直接帶入model.fit()裡面，取代原本把dataGenerator裡的資料存到x變數再帶入model.fit()的方式，比原本的方式更準確、更省空間，但更花時間，每次epoch多花了快兩倍的時間，訓練一次就花了快一小時，我也不確定這樣做為什麼會更準確，但從數據上來看是這樣。在訓練AI的過程中，不知道為什麼有種「我訓練AI，AI訓練我」的感覺，因為每次調整一個參數，我再根據AI訓練出來的結果決定參數要調多少會比較好，就這樣一直反覆測試、反覆測試，感覺就跟AI在做的事差不多。我想，這大概就是所謂的「學習」吧！而我這時也想到，那既然我做的事跟AI差不多，那麼「AI是否也能訓練AI呢？」
