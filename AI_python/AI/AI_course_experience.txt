上完這次的課程，同樣也是真的學到非常多的知識，不論是對於AI的理解以及一些AI的算法像是Gradient Descend, CNN, RNN都有更深入的了解。自己本來是對AI沒什麼興趣的，也沒有寫過AI相關的程式，只是最近AI很熱門再加上大學剛好考上淡江人工智慧學系，所以才報名了這個課程。但是上完課後，反而對AI更有興趣了！我很喜歡線上課程的形式，只是Google Meet不能直接傳圖片比較可惜，課程的內容都淺顯易懂，老師也會帶我們一步步講解，讓我們能更理解課程的內容，老師真的很用心，簡報做得很精美，也都會有耐心地回答學生的問題，態度也很和藹可親，我覺得是一位能激起學生求知慾的教授。

我最喜歡這個課程的部份是課程最後的驗收，雖然老師是因為發證書需要有一些標準才有這個環節的，但是因為我很喜歡動手去實作，因為實作總是能學到很多東西，我也很享受實作中一步步解決問題的過程，再加上驗收通過的標準也不難，只要準確率超過75%就可以了。這次的驗收我花了最大的努力去完成，從題目公佈的那天起，我就開始在訓練model，一開始我只是隨便加幾層卷積，結果就有75~76%準確率了，但是我覺得還不夠好，想說至少要到80%，所以我就一直不斷地trial and error，努力結合課程以及自己的知識把準確率推到最高。不過因為我訓練太多次了，所以colab不讓我用GPU，要等幾個小時才能用，所以我還用別的帳號去跑，結果訓練太多也用不了GPU了，最後總共被鎖了3次，而且沒有GPU的話，一次epoch要跑1小時左右，用GPU只要30s左右，速度差了一百多倍！所以花了很多時間在訓練跟等解鎖GPU。但是，努力過後的果實總是甜美的，經過了2天2夜的思考與測試，最後驗收當天測出的最高準確率是89.26％！快將近到達90％，而其他人主要是在75~82％之間，可以看出我花了很多時間去做調整與訓練我的model。為什麼我的model跟別人的model會有這麼大的差異呢？我覺得原因可能是以下3點：model架構、資料強度與資料量、訓練方式。

首先，model架構我是參考了VGG16的架構，並且用4次迴圈去建卷積層，每次迴圈都讓卷積核心數乘兩倍（初始為64），並加2~3層卷積還有一層BatchNormalization以及MaxPooling2D。最後再做flatten，用兩層Dense每層一次Dropout(0.1)，減少Overfitting，model 總共約24層。相較之下，其他人的卷積層就不像我的這麼複雜，可能就像我一開始一樣就只加3~4層卷積，這樣雖然可以到75%，但是要更好的話，可以再更複雜。但是也不是越複雜越好，過於複雜好像會導致Overfitting的情況。以我這個架構的話大約可以到78～80%左右的準確率。

再來，資料強度與資料量的部份，一開始我也是直接用原始的資料去訓練，但是這樣一樣只有78~80%左右的準確率，之後考慮到資料強度，可以用老師教過的ImageDataGenerator，可以對資料做一些transform，增加資料強度，可讓準確率到81~82%。但是我又考慮到資料量的部份，我覺得一倍的資料量太少了，所以我就把原始的資料再複製一份，然後再做資料增強，這樣就可以得到兩倍的資料且都不會重複，那時沒有想太多就直接這樣做了，但之後驗收後有問老師這樣重複一份資料再增強會不會比較好，老師說因為他也沒有這樣試過，所以他也不太確定，但老師認為應該不會，因為資料都是一樣的只是多了一倍，增強的資料應該也是會一樣，最後說我可以去測試看看。整個課程結束後我有自己去測試過了，結論就是用重複一份資料再做增強的方式，確實可以提昇準確率，大約可以高個2~3%，我認為這是因為ImageDataGenerator不管資料是不是一樣都會隨機產生出不同的資料出來，所以出來的資料也會不同，我也實際將資料量簡化為1個並複製再做增強，出來的2個資料也是不一樣的，但看得出來是根據原本的資料來做變化，像是有一張圖片有翻轉、偏左，另一張可能是沒翻轉、偏右。當時我就用了這個方法讓準確率到了84~85%。

最後，訓練的部份，我是分兩次訓練，這是因為我一開始只有訓練一次，可能是用增強的資料，或是用原始的資料。但是後來我意識到增強過的資料跟原始的資料都是不同的資料，兩份都拿來訓練應該會比較好，所以我決定分兩次訓練。第一次訓練是用增強過的兩倍資料，然後第二次再用原始資料並用更小的學習率(0.0003)去趨近原始的資料，其實感覺有點像是考試先給你難的考題，然後再給你原本的考題，然後你就會覺得原本的考題比較簡單的概念。然後每一次訓練跑40Epochs，還有設一個EarlyStopping(monitor='val_loss', patience = 8)，即為val_loss在8次Epochs內沒有比較好就停止訓練。我用這樣的方法，讓準確率再提昇3~4%，差不多是88~89%。看到89.26%的當下真的很感動，我會得到這個89%，並不是因為我比較聰明，也不是我運氣比較好，而是我願意花時間在這次的作業上，並且在最後的兩天展現課程中所得到的知識，在這兩天內總共訓練的時間至少超過了十小時，也寫了快十個版本，最後終於得到還不錯的結果，而且有些方法還是靠自己想的，這使我得到很大的成就感，也燃起了我對AI領域的興趣，更讓我再次體會到了動手實作的魅力。

最後的最後，真的非常感謝這四周授課的兩位教授，短短四周內真的學到了很多知識，讓我有能力可以處理一些資訊或是製作一些工具，提升自己的價值。在這四周內我也落實coding365的精神，幾乎每天都會寫一些程式，不論是課堂的練習，還是自己想寫的小工具，甚至有一週還花了23小時的時間在coding。希望課程的時間或週次可以再長一些，因為兩位教授的課總是能激起我們的求知慾，想要越學越多。尤其是AI的課程，雖然李教授已經教到比原本預定的課程還多出四個章節了，但是感覺AI還有非常多的東西可以講。總之，最後還是非常感謝北科大提供如此高質量的課程，讓我這四周過得非常有意義！

p.s. 課程結束後，又花幾個小時將準確率提升到最高93.1%，比原本高了3~4%，方式僅是將dataGenerator直接帶入model.fit()裡面，取代原本把dataGenerator裡的資料存到x變數再帶入model.fit()的方式，比原本的方式更準確、更省空間，但更花時間，每次epoch多花了快兩倍的時間，訓練一次就花了快一小時，我也不確定這樣做為什麼會更準確，但從數據上來看是這樣。在訓練AI的過程中，不知道為什麼有種「我訓練AI，AI訓練我」的感覺，因為每次調整一個參數，我再根據AI訓練出來的結果決定參數要調多少會比較好，就這樣一直反覆測試、反覆測試，感覺就跟AI在做的事差不多。我想，這大概就是所謂的「學習」吧！而我這時也想到，那既然我做的事跟AI差不多，那麼「AI是否也能訓練AI呢？」



このコースの後、AI の理解や、勾配降下、CNN、RNN などの一部の AI アルゴリズムについての理解が深まり、本当に多くの知識を学びました。 もともとAIには興味がなかったし、AI関連のプログラムを書いたこともなかったのですが、ただ最近AIがすごく流行っているということで、淡江大学の人工知能学科に入学できたので、この講座を受講しました。 でも授業を受けてからAIにもっと興味が湧きました！ オンラインコースの形式はとても気に入っていますが、Google Meet で写真を直接アップロードできないのが残念です。コースの内容はわかりやすく、先生が一つ一つ丁寧に説明してくれるので、より良い学習ができます。授業の内容がよく分かります 先生は本当に勉強家で、ブリーフィングも丁寧で学生の質問にも丁寧に答えて下さり、態度もとても愛想が良く、学生の知識欲を刺激してくれる先生だと思います。

このコースで私のお気に入りの部分は、コースの最終的な承認です。証明書の発行にはいくつかの基準が必要なため、教師がこのリンクを持っていますが、私は手動で行うのが好きなため、実践を通じて常に多くのことを学ぶことができるからです。 ,また、実際に問題を解決していく段階的なプロセスも楽しいです。合格基準は正解率が 75% を超えていれば難しくありません。 私はこの受け入れテストを完了するために最善を尽くしました。トピックが発表された日から、モデルのトレーニングを開始しました。最初はランダムに数層の畳み込みを追加しただけで、結果は 75 ～ 76% の精度でしたが、これでは不十分だと思いますし、少なくとも80％は言いたいので、講座や自分の知識を組み合わせて精度を最高まで上げようと試行錯誤しています。 しかし、何度もトレーニングしたため、colab は GPU を使用できず、使用するには数時間待たなければならないため、依然として別のアカウントを使用して実行しています。 GPU をトレーニングしすぎて、最終的にロックされたことが 3 回あり、GPU がない場合、エポックを実行するのに約 1 時間かかりますが、GPU を使用すると約 30 秒しかかからず、速度は 1 秒以上です何百倍も悪い！ そのため、トレーニングと GPU のロックが解除されるまでの待機に多くの時間を費やしました。 しかし、努力の成果は常に甘く、2 日 2 晩考えてテストした結果、最終合格日に測定された最高正解率は 89.26% でした。 ほぼ90％に達していますが、その他は75～82％が中心で、モデルの調整とトレーニングに多くの時間を費やしたことがわかります。 私のモデルと他の人のモデルの間にこれほど大きな違いがあるのはなぜですか? その理由としては、モデルの構造、データの強度とデータ量、学習方法の3点が考えられます。

まず、モデルのアーキテクチャは VGG16 アーキテクチャを参照し、畳み込み層を構築するのに 4 つのループを使用します。各ループは畳み込みコアの数を 2 倍にし (最初は 64)、さらに 2 ～ 3 層の畳み込みを追加します。 BatchNormalization と MaxPooling2D のレイヤー。 最後に、平坦化を行い、ドロップアウト (0.1) の各レイヤーに 2 つの密のレイヤーを使用し、オーバーフィッティングを減らし、モデルには合計約 24 のレイヤーがあります。 対照的に、他の人の畳み込み層は私ほど複雑ではないので、最初と同じように畳み込み層を 3 ～ 4 層追加するだけで、75% に達する可能性がありますが、それが改善される場合は、もう一度追加することもできます。 . より複雑です。 しかし、複雑であればあるほど良いため、複雑すぎると過学習につながるようです。 私のアーキテクチャでは、精度率は約 78 ～ 80% に達します。

次に、データ強度とデータ量の部分ですが、私も最初は元のデータを直接学習に使用しましたが、正解率は78～80%程度でした。後は、データ強度を考慮して、教えられたImageDataGeneratorを使用できます教師によると、データに何らかの変換を加えてデータの強度を高めると、正解率が 81 ～ 82% に達する可能性があります。 しかし、データ量も考慮しました。データ量が 2 倍では少なすぎると思うので、元のデータのコピーをもう 1 つ作成し、データを拡張して、2 倍のデータを取得できるようにしました。その時はあまり考えずにやりましたが、合格後に先生に「もう一回繰り返して強化した方が良いのでは？」と聞いたところ、先生は「やったことがないから」と言いました。以前はそうではありませんでしたが、先生はそうすべきではないと考え、情報は同じですが2倍になっており、強化された情報も同じであるはずであり、最終的にはテストに行って確認できると言った。 一通りの講座が終わった後、自分で試してみたところ、データのコピーと強化を繰り返すことで確かに2～3%程度正解率が向上するという結論になりました。データは同じでもランダムに別のデータが生成されるため、データは異なります。実際にはデータを1に簡略化してコピーして強化しました。2つのデータも異なりますが、オリジナルをベースにしていることがわかりますデータは変更を加えるために使用されます。たとえば、1 つの画像を反転して左にシフトする一方で、もう 1 つの画像を反転せずに右にシフトすることができます。 当時はこの方法で正解率84～85％を達成しました。

最後にトレーニング部分ですが、強化データまたはオリジナルデータのいずれかを使用して最初に 1 回しかトレーニングしなかったため、2 つのトレーニング セッションに分けました。 しかし、強化されたデータは元のデータとは異なるため、両方をトレーニングに使用した方が良いことに気づき、2 回トレーニングすることにしました。 最初のトレーニングでは 2 倍の強化データを使用し、次に元のデータを使用して、より小さい学習率 (0.0003) を使用して元のデータに近づけます。実際、最初に難しい試験問題を与えるような感じです。 . 次に、オリジナルのテスト問題を与えると、オリジナルのテスト問題の概念がより単純であると感じるでしょう。 次に、各トレーニングで 40 エポックを実行し、EarlyStopping(monitor='val_loss', pain = 8) を設定します。つまり、8 エポック以内に val_loss が改善しない場合はトレーニングを停止します。 この方法を使用すると、正解率がさらに 3 ～ 4% 向上し、ほぼ 88 ～ 89% になります。 現時点で 89.26% という数字を見るのは本当に感動的です。私はこの 89% を達成するでしょう。私が賢いからでも、幸運だからでもなく、この課題に喜んで時間を費やすからです。そして、最後の 2 日間でコースで得た知識を示し、この 2 日間の合計トレーニング時間は少なくとも 10 時間で、私も 10 近くのバージョンを書き、最終的に良い結果が得られましたが、いくつかの方法はまだ自分で考えていました。とても達成感があり、AI分野への興味も湧き、実践の魅力を改めて実感しました。

最後に、この 4 週間で教えてくれた 2 人の教授に本当に感謝しています。わずか 4 週間で多くの知識を学び、情報を処理したり、自分の価値を高めるためのツールを作成したりすることができました。 過去 4 週間、私もコーディング 365 の精神を実践してきました。授業の演習であれ、書きたいガジェットであれ、ほぼ毎日いくつかのプログラムを書きました。コーディングに週に 23 時間を費やしたこともあります。 二人の教授の授業はいつでも私たちの知識欲を刺激し、もっと学びたいと思わせることができるので、コースの時間または週数がもっと長くてもよいと思います。 特にAIコースは、李教授が当初予定していたコースよりもすでに4章多く教えていますが、AIについてはまだまだ語るべきことがたくさんあると感じています。 最後になりますが、このような質の高い授業を提供してくださった北京科技大学に感謝し、とても有意義な4週間となりました！

p.s. 講座終了後、さらに数時間かけて正答率を最高の93.1%（元より3～4%高い）まで上げましたが、その方法はdataGeneratorをmodel.fit()に直接取り込むだけです。 dataGenerator 内の元のデータを置き換える x 変数に保存してから model.fit() に取り込む方法は、元の方法より正確でスペースも節約できますが、時間がかかります。それぞれに 2 倍の時間がかかります。エポック、トレーニングに 1 回、時間、なぜこの方が正確なのかはわかりませんが、データからはそうなるようです。 AIを訓練する過程で、なぜ「私がAIを訓練し、AIが私を訓練する」という感情が生まれるのかわかりません。パラメーターを調整するたびに、その結​​果に応じてパラメーターをどの程度調整するかを決定するからです。 AIのトレーニング、それで終わりです 何度もテストを繰り返して、AIがやっているような感じです。 おそらくこれがいわゆる「学び」なのではないかと思います！ そして、私がやっていることはAIと似ているので、「AIもAIを育てることができるのではないか？」とこの時に思いました。



