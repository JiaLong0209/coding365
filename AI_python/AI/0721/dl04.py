# -*- coding: utf-8 -*-
"""DL04.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13ohImAv_oXd0meupRbXpI7R-tomfLMha
"""

import pandas as pd

train_df = pd.read_csv("drive/MyDrive/00AI/sign_mnist_train.csv")
valid_df = pd.read_csv("drive/MyDrive/00AI/sign_mnist_test.csv")
train_label = train_df['label']
valid_label = valid_df['label']
del train_df['label']
del valid_df['label']

# Separate out our image vectors
train_image = train_df.values
valid_image = valid_df.values

train_image = train_image.reshape(-1,28,28,1) #灰階=1 RGB=3
valid_image = valid_image.reshape(-1,28,28,1)
train_image.shape, valid_image.shape
#-1表示需要根據張量總元素不變的規則
#-1表示自動推斷該維度的長度。

import matplotlib.pyplot as plt
plt.figure(figsize=(10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_image[0+i], cmap=plt.cm.binary)
    plt.xlabel(train_label[0+i])
plt.show()

train_image = train_image / 255
valid_image = valid_image / 255

train_label.shape, train_label[0]

#import tensorflow.keras as keras
import tensorflow as tf
keras=tf.keras

num_classes = 25
train_label = keras.utils.to_categorical(train_label, num_classes)
valid_label = keras.utils.to_categorical(valid_label, num_classes)

train_label[0:5]

model=tf.keras.models.Sequential()
layers=tf.keras.layers

model.add(layers.Conv2D(75, (3, 3), strides=1, padding="same", activation="relu",input_shape=(28, 28, 1)))#padding=same旁邊填入相同數值
model.add(layers.BatchNormalization())
model.add(layers.MaxPool2D((2, 2), strides=2, padding="same"))
model.add(layers.Conv2D(50, (3, 3), strides=1, padding="same", activation="relu"))
model.add(layers.Dropout(0.2))
model.add(layers.BatchNormalization())
model.add(layers.MaxPool2D((2, 2), strides=2, padding="same"))
model.add(layers.Conv2D(25, (3, 3), strides=1, padding="same", activation="relu"))
model.add(layers.BatchNormalization())
model.add(layers.MaxPool2D((2, 2), strides=2, padding="same"))
model.add(layers.Flatten())
model.add(layers.Dense(units=512, activation="relu"))
model.add(layers.Dropout(0.3))
model.add(layers.Dense(units=num_classes, activation="softmax"))

model.summary()

model.compile(loss="categorical_crossentropy", metrics=["accuracy"])

model.fit(train_image, train_label, epochs=3, verbose=1, validation_data=(valid_image, valid_label))

#from tensorflow.keras.preprocessing.image import ImageDataGenerator
datagen = tf.keras.preprocessing.image.ImageDataGenerator(
    rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)
    zoom_range=0.1,  # Randomly zoom image
    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)
    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)
    horizontal_flip=True,  # randomly flip images horizontally
    vertical_flip=False, # Don't randomly flip images vertically
)

import numpy as np
batch_size = 32
img_iter = datagen.flow(train_image, train_label, batch_size=batch_size)

x, y = img_iter.next()
x.shape, y.shape

x[0].shape

plt.imshow(np.squeeze(x[0]))

x, y = img_iter.next()
fig, ax = plt.subplots(nrows=4, ncols=8)
for i in range(batch_size):
    image = x[i]
    ax.flatten()[i].imshow(np.squeeze(image))
plt.show()

datagen.fit(train_image)

train_image.shape

model.compile(loss="categorical_crossentropy", metrics=["accuracy"])

model.fit(img_iter,epochs=20,
          steps_per_epoch=len(train_image)/batch_size, # Run same number of steps we would if we were not using a generator.
          validation_data=(valid_image, valid_label))

#儲存模型
model.save('drive/MyDrive/00AI/asl_model')